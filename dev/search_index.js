var documenterSearchIndex = {"docs":
[{"location":"references/#References","page":"References","title":"References","text":"","category":"section"},{"location":"references/","page":"References","title":"References","text":"","category":"page"},{"location":"api/layers/#Layers","page":"General Purpose Layers","title":"Layers","text":"","category":"section"},{"location":"api/layers/","page":"General Purpose Layers","title":"General Purpose Layers","text":"DEQChain\nMultiParallelNet","category":"page"},{"location":"api/layers/#FastDEQ.DEQChain","page":"General Purpose Layers","title":"FastDEQ.DEQChain","text":"DEQChain(pre_deq, deq, post_deq)\nDEQChain(layers...)\n\nA Sequential Model containing a DEQ.\n\nnote: Note\nThe Model should contain exactly 1 AbstractDEQ Layer\n\n\n\n\n\n","category":"type"},{"location":"api/layers/#FastDEQ.MultiParallelNet","page":"General Purpose Layers","title":"FastDEQ.MultiParallelNet","text":"MultiParallelNet(layers...)\nMultiParallelNet(layers::Tuple)\nMultiParallelNet(layers::Vector)\n\nCreates a MultiParallelNet mostly used for MultiScale Models. It takes a list of inputs and passes all of them through each layer and returns a tuple of outputs.\n\nExample\n\nModel := MultiParallelNet(L1, L2, L3)\n\nModel(X1, X2) := (Model.L1(X1, X2), Model.L2(X1, X2), Model.L3(X1, X2))\n\n\n\n\n\n","category":"type"},{"location":"api/deqs/#Deep-Equilibrium-Models","page":"DEQ Layers","title":"Deep Equilibrium Models","text":"","category":"section"},{"location":"api/deqs/#Standard-Models","page":"DEQ Layers","title":"Standard Models","text":"","category":"section"},{"location":"api/deqs/","page":"DEQ Layers","title":"DEQ Layers","text":"DeepEquilibriumNetwork\nSkipDeepEquilibriumNetwork","category":"page"},{"location":"api/deqs/#FastDEQ.DeepEquilibriumNetwork","page":"DEQ Layers","title":"FastDEQ.DeepEquilibriumNetwork","text":"DeepEquilibriumNetwork(model, solver; jacobian_regularization::Bool=false,\n                       p=nothing, sensealg=SteadyStateAdjoint(0.1f0, 0.1f0, 10),\n                       kwargs...)\n\nDeep Equilibrium Network as proposed in Shaojie Bai, J. Zico Kolter, Vladlen Koltun (2019)\n\nArguments\n\nmodel: Explicit Neural Network which takes 2 inputs\nsolver: Solver for the optimization problem (See: ContinuousDEQSolver & DiscreteDEQSolver)\njacobian_regularization: If true, Jacobian Loss is computed and stored in the DeepEquilibriumSolution\np: Optional parameters for the model\nsensealg: See SteadyStateAdjoint\nkwargs: Additional Parameters that are directly passed to solve\n\nExample\n\nmodel = DeepEquilibriumNetwork(\n    Parallel(\n        +,\n        Dense(2, 2; bias=false),\n        Dense(2, 2; bias=false)\n    ),\n    ContinuousDEQSolver(VCABM3(); abstol=0.01f0, reltol=0.01f0)\n)\n\nmodel(rand(Float32, 2, 1))\n\nSee also: SkipDeepEquilibriumNetwork, MultiScaleDeepEquilibriumNetwork, MultiScaleSkipDeepEquilibriumNetwork\n\n\n\n\n\n","category":"type"},{"location":"api/deqs/#FastDEQ.SkipDeepEquilibriumNetwork","page":"DEQ Layers","title":"FastDEQ.SkipDeepEquilibriumNetwork","text":"SkipDeepEquilibriumNetwork(model, shortcut, solver; p=nothing, jacobian_regularization::Bool=false,\n                           sensealg=SteadyStateAdjoint(0.1f0, 0.1f0, 10), kwargs...)\nSkipDeepEquilibriumNetwork(model, solver; p=nothing, jacobian_regularization::Bool=false,\n                           sensealg=SteadyStateAdjoint(0.1f0, 0.1f0, 10), kwargs...)\n\nSkip Deep Equilibrium Network as proposed in Avik Pal, Alan Edelman, Christopher Rackauckas (2022)\n\nArguments\n\nmodel: Explicit Neural Network which takes 2 inputs\nshortcut: Shortcut for the network (If not given, then we create SkipDEQV2)\nsolver: Solver for the optimization problem (See: ContinuousDEQSolver & DiscreteDEQSolver)\njacobian_regularization: If true, Jacobian Loss is computed and stored in the DeepEquilibriumSolution\np: Optional parameters for the model\nsensealg: See SteadyStateAdjoint\nkwargs: Additional Parameters that are directly passed to solve\n\nExample\n\n# SkipDEQ\nmodel = SkipDeepEquilibriumNetwork(\n    Parallel(\n        +,\n        Dense(2, 2; bias=false),\n        Dense(2, 2; bias=false)\n    ),\n    Dense(2, 2),\n    ContinuousDEQSolver(VCABM3(); abstol=0.01f0, reltol=0.01f0)\n)\n\nmodel(rand(Float32, 2, 1))\n\n# SkipDEQV2\nmodel = SkipDeepEquilibriumNetwork(\n    Parallel(\n        +,\n        Dense(2, 2; bias=false),\n        Dense(2, 2; bias=false)\n    ),\n    ContinuousDEQSolver(VCABM3(); abstol=0.01f0, reltol=0.01f0)\n)\n\nmodel(rand(Float32, 2, 1))\n\nSee also: DeepEquilibriumNetwork, MultiScaleDeepEquilibriumNetwork, MultiScaleSkipDeepEquilibriumNetwork\n\n\n\n\n\n","category":"type"},{"location":"api/deqs/#MultiScale-Models","page":"DEQ Layers","title":"MultiScale Models","text":"","category":"section"},{"location":"api/deqs/","page":"DEQ Layers","title":"DEQ Layers","text":"MultiScaleDeepEquilibriumNetwork\nMultiScaleSkipDeepEquilibriumNetwork","category":"page"},{"location":"api/deqs/#FastDEQ.MultiScaleDeepEquilibriumNetwork","page":"DEQ Layers","title":"FastDEQ.MultiScaleDeepEquilibriumNetwork","text":"MultiScaleDeepEquilibriumNetwork(main_layers::Tuple, mapping_layers::Matrix, solver;\n                                 post_fuse_layers::Union{Tuple,Nothing}=nothing, p=nothing,\n                                 sensealg=SteadyStateAdjoint(0.1f0, 0.1f0, 10), kwargs...)\n\nMultiscale Deep Equilibrium Network as proposed in Shaojie Bai, Vladlen Koltun, J. Zico Kolter (2020)\n\nArguments\n\nmain_layers: Tuple of Explicit Neural Networks. The first network needs to take 2 inputs, the other ones only take 1 input\nmapping_layers: Matrix of Explicit Neural Networks. The (i j)^th network takes the output of i^th main_layer                   and passes it to the j^th main_layer\nsolver: Solver for the optimization problem (See: ContinuousDEQSolver & DiscreteDEQSolver)\npost_fuse_layers: Tuple of Explicit Neural Networks. Applied after the mapping_layers (Default: nothing)\np: Optional parameters for the model\nsensealg: See SteadyStateAdjoint\nkwargs: Additional Parameters that are directly passed to solve\n\nExample\n\nmodel = MultiScaleDeepEquilibriumNetwork(\n    (\n        Parallel(+, Dense(4, 4, tanh_fast), Dense(4, 4, tanh_fast)),\n        Dense(3, 3, tanh_fast), Dense(2, 2, tanh_fast),\n        Dense(1, 1, tanh_fast)\n    ),\n    [\n        NoOpLayer() Dense(4, 3, tanh_fast) Dense(4, 2, tanh_fast) Dense(4, 1, tanh_fast);\n        Dense(3, 4, tanh_fast) NoOpLayer() Dense(3, 2, tanh_fast) Dense(3, 1, tanh_fast);\n        Dense(2, 4, tanh_fast) Dense(2, 3, tanh_fast) NoOpLayer() Dense(2, 1, tanh_fast);\n        Dense(1, 4, tanh_fast) Dense(1, 3, tanh_fast) Dense(1, 2, tanh_fast) NoOpLayer()\n    ],\n    ContinuousDEQSolver(VCABM3(); abstol=0.01f0, reltol=0.01f0),\n)\n\nmodel(rand(Float32, 4, 1))\n\nSee also: DeepEquilibriumNetwork, SkipDeepEquilibriumNetwork, MultiScaleSkipDeepEquilibriumNetwork\n\n\n\n\n\n","category":"type"},{"location":"api/deqs/#FastDEQ.MultiScaleSkipDeepEquilibriumNetwork","page":"DEQ Layers","title":"FastDEQ.MultiScaleSkipDeepEquilibriumNetwork","text":"MultiScaleSkipDeepEquilibriumNetwork(main_layers::Tuple, mapping_layers::Matrix, shortcut_layers::Tuple,\n                                     solver; post_fuse_layers::Union{Tuple,Nothing}=nothing, p=nothing,\n                                     sensealg=SteadyStateAdjoint(0.1f0, 0.1f0, 10), kwargs...)\nMultiScaleSkipDeepEquilibriumNetwork(main_layers::Tuple, mapping_layers::Matrix, solver;\n                                     post_fuse_layers::Union{Tuple,Nothing}=nothing, p=nothing,\n                                     sensealg=SteadyStateAdjoint(0.1f0, 0.1f0, 10), kwargs...)\n\nMultiscale Deep Equilibrium Network as proposed in Shaojie Bai, Vladlen Koltun, J. Zico Kolter (2020)\n\nArguments\n\nmain_layers: Tuple of Explicit Neural Networks. The first network needs to take 2 inputs, the other ones only take 1 input\nmapping_layers: Matrix of Explicit Neural Networks. The (i j)^th network takes the output of i^th main_layer                   and passes it to the j^th main_layer\nshortcut_layers: Shortcuts for the network (If not given, then we create SkipDEQV2)\nsolver: Solver for the optimization problem (See: ContinuousDEQSolver & DiscreteDEQSolver)\npost_fuse_layers: Tuple of Explicit Neural Networks. Applied after the mapping_layers (Default: nothing)\np: Optional parameters for the model\nsensealg: See SteadyStateAdjoint\nkwargs: Additional Parameters that are directly passed to solve\n\nExample\n\n# MSkipDEQ\nmodel = MultiScaleSkipDeepEquilibriumNetwork(\n    (\n        Parallel(+, Dense(4, 4, tanh_fast), Dense(4, 4, tanh_fast)),\n        Dense(3, 3, tanh_fast), Dense(2, 2, tanh_fast),\n        Dense(1, 1, tanh_fast)\n    ),\n    [\n        NoOpLayer() Dense(4, 3, tanh_fast) Dense(4, 2, tanh_fast) Dense(4, 1, tanh_fast);\n        Dense(3, 4, tanh_fast) NoOpLayer() Dense(3, 2, tanh_fast) Dense(3, 1, tanh_fast);\n        Dense(2, 4, tanh_fast) Dense(2, 3, tanh_fast) NoOpLayer() Dense(2, 1, tanh_fast);\n        Dense(1, 4, tanh_fast) Dense(1, 3, tanh_fast) Dense(1, 2, tanh_fast) NoOpLayer()\n    ],\n    (\n        Dense(4, 4, tanh_fast),\n        Dense(4, 3, tanh_fast),\n        Dense(4, 2, tanh_fast),\n        Dense(4, 1, tanh_fast)\n    ),\n    ContinuousDEQSolver(VCABM3(); abstol=0.01f0, reltol=0.01f0),\n)\n\nmodel(rand(Float32, 4, 1))\n\n\n# MSkipDEQV2\nmodel = MultiScaleSkipDeepEquilibriumNetwork(\n    (\n        Parallel(+, Dense(4, 4, tanh_fast), Dense(4, 4, tanh_fast)),\n        Dense(3, 3, tanh_fast), Dense(2, 2, tanh_fast),\n        Dense(1, 1, tanh_fast)\n    ),\n    [\n        NoOpLayer() Dense(4, 3, tanh_fast) Dense(4, 2, tanh_fast) Dense(4, 1, tanh_fast);\n        Dense(3, 4, tanh_fast) NoOpLayer() Dense(3, 2, tanh_fast) Dense(3, 1, tanh_fast);\n        Dense(2, 4, tanh_fast) Dense(2, 3, tanh_fast) NoOpLayer() Dense(2, 1, tanh_fast);\n        Dense(1, 4, tanh_fast) Dense(1, 3, tanh_fast) Dense(1, 2, tanh_fast) NoOpLayer()\n    ],\n    ContinuousDEQSolver(VCABM3(); abstol=0.01f0, reltol=0.01f0),\n)\n\nmodel(rand(Float32, 4, 1))\n\nSee also: DeepEquilibriumNetwork, SkipDeepEquilibriumNetwork, MultiScaleDeepEquilibriumNetwork\n\n\n\n\n\n","category":"type"},{"location":"api/nlsolve/#NonLinear-Solvers","page":"Non Linear Solvers","title":"NonLinear Solvers","text":"","category":"section"},{"location":"api/nlsolve/","page":"Non Linear Solvers","title":"Non Linear Solvers","text":"We provide the following NonLinear Solvers for DEQs. These are compatible with GPUs.","category":"page"},{"location":"api/nlsolve/","page":"Non Linear Solvers","title":"Non Linear Solvers","text":"note: Note\nIf you are looking for general purpose nonlinear solvers, we recommend checking out NonlinearSolve.jl","category":"page"},{"location":"api/nlsolve/","page":"Non Linear Solvers","title":"Non Linear Solvers","text":"BroydenSolver\nLimitedMemoryBroydenSolver","category":"page"},{"location":"api/nlsolve/#FastDEQ.BroydenSolver","page":"Non Linear Solvers","title":"FastDEQ.BroydenSolver","text":"BroydenSolver(; T=Float32, device, original_dims::Tuple{Int,Int}, batch_size, maxiters::Int=50, ϵ::Real=1e-6,\n              abstol::Union{Real,Nothing}=nothing, reltol::Union{Real,Nothing}=nothing)\n\nBroyden Solver (Charles G Broyden (1965)) for solving Discrete DEQs. It is recommended to use LimitedMemoryBroydenSolver for better performance.\n\nArguments\n\nT: The type of the elements of the vectors. (Default: Float32)\ndevice: The device to use. Pass gpu to use the GPU else pass cpu.\noriginal_dims: Dimensions to reshape the arrays into (excluding the batch dimension).\nbatch_size: The batch size of the problem. Your inputs can have a different batch size, but having               them match allows us to efficiently cache internal statistics without reallocation.\nmaxiters: Maximum number of iterations to run.\nϵ: Tolerance for convergence.\nabstol: Absolute tolerance.\nreltol: Relative tolerance. (This value is ignored by BroydenSolver at the moment)\n\nSee also: LimitedMemoryBroydenSolver\n\n\n\n\n\n","category":"type"},{"location":"api/nlsolve/#FastDEQ.LimitedMemoryBroydenSolver","page":"Non Linear Solvers","title":"FastDEQ.LimitedMemoryBroydenSolver","text":"LimitedMemoryBroydenSolver(; T=Float32, device, original_dims::Tuple{Int,Int}, batch_size, maxiters::Int=50,\n                           ϵ::Real=1e-6, criteria::Symbol=:reltol, abstol::Union{Real,Nothing}=nothing,\n                           reltol::Union{Real,Nothing}=nothing\n\nLimited Memory Broyden Solver (Shaojie Bai, Vladlen Koltun, J. Zico Kolter (2020)) for solving Discrete DEQs.\n\nArguments\n\nT: The type of the elements of the vectors. (Default: Float32)\ndevice: The device to use. Pass gpu to use the GPU else pass cpu.\noriginal_dims: Dimensions to reshape the arrays into (excluding the batch dimension).\nbatch_size: The batch size of the problem. Your inputs can have a different batch size, but having               them match allows us to efficiently cache internal statistics without reallocation.\nmaxiters: Maximum number of iterations to run.\nϵ: Tolerance for convergence.\ncriteria: The criteria to use for convergence. Can be :reltol or :abstol.\nabstol: Absolute tolerance.\nreltol: Relative tolerance.\n\nSee also: BroydenSolver\n\n\n\n\n\n","category":"type"},{"location":"#FastDEQ:-(Fast)-Deep-Equlibrium-Networks","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FastDEQ: (Fast) Deep Equlibrium Networks","text":"","category":"section"},{"location":"","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FastDEQ: Fast Deep Equilibrium Networks","text":"FastDEQ.jl is a framework built on top of DifferentialEquations.jl and Flux.jl enabling the efficient training and inference for Deep Equilibrium Networks (Infinitely Deep Neural Networks).","category":"page"},{"location":"#Installation","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"Installation","text":"","category":"section"},{"location":"","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FastDEQ: Fast Deep Equilibrium Networks","text":"Currently the package is not registered and requires manually installing a few dependencies. We are working towards upstream fixes which will make installation easier","category":"page"},{"location":"","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FastDEQ: Fast Deep Equilibrium Networks","text":"] add https://github.com/SciML/DiffEqSensitivity.jl.git#ap/fastdeq\n] add https://github.com/avik-pal/FluxExperimental.jl.git#main\n] add https://github.com/SciML/FastDEQ.jl","category":"page"},{"location":"#Citation","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"Citation","text":"","category":"section"},{"location":"","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FastDEQ: Fast Deep Equilibrium Networks","text":"If you are using this project for research or other academic purposes consider citing our paper:","category":"page"},{"location":"","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FastDEQ: Fast Deep Equilibrium Networks","text":"@misc{pal2022mixing,\n      title={Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite Time Neural ODEs (Continuous DEQs)}, \n      author={Avik Pal and Alan Edelman and Christopher Rackauckas},\n      year={2022},\n      eprint={2201.12240},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}","category":"page"},{"location":"","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FastDEQ: Fast Deep Equilibrium Networks","text":"For specific algorithms, check the respective documentations and cite the corresponding papers.","category":"page"},{"location":"#FAQs","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FAQs","text":"","category":"section"},{"location":"#How-do-I-reproduce-the-experiments-in-the-paper-–-*Mixing-Implicit-and-Explicit-Deep-Learning-with-Skip-DEQs-and-Infinite-Time-Neural-ODEs-(Continuous-DEQs)*?","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"How do I reproduce the experiments in the paper – Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite Time Neural ODEs (Continuous DEQs)?","text":"","category":"section"},{"location":"","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FastDEQ: Fast Deep Equilibrium Networks","text":"Check out the ap/paper branch for the code corresponding to that paper.","category":"page"},{"location":"#Are-there-some-tutorials?","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"Are there some tutorials?","text":"","category":"section"},{"location":"","page":"FastDEQ: Fast Deep Equilibrium Networks","title":"FastDEQ: Fast Deep Equilibrium Networks","text":"We are working on adding some in the near future. In the meantime, please checkout the experiments directory in the ap/paper branch. You can also check test/runtests.jl for some simple examples.","category":"page"},{"location":"api/misc/#Miscellaneous","page":"Miscellaneous","title":"Miscellaneous","text":"","category":"section"},{"location":"api/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"SteadyStateAdjoint\nDeepEquilibriumSolution\nget_and_clear_nfe!\ncompute_deq_jacobian_loss\nNormalInitializer\nSupervisedLossContainer","category":"page"},{"location":"api/misc/#DiffEqSensitivity.SteadyStateAdjoint","page":"Miscellaneous","title":"DiffEqSensitivity.SteadyStateAdjoint","text":"SteadyStateAdjoint(reltol, abstol, maxiters; autojacvec=ZygoteVJP(),\n                   linsolve=KrylovJL_GMRES(; rtol=reltol, atol=abstol, itmax=maxiters))\n\nCreates SteadyStateAdjoint (Steven G Johnson (2006)) with sensible defaults.\n\nArguments\n\nreltol: Relative tolerance.\nabstol: Absolute tolerance.\nmaxiters: Maximum number of iterations.\nautojacvec: Which backend to use for VJP.\nlinsolve: Linear Solver from LinearSolve.jl.\n\n\n\n\n\n","category":"type"},{"location":"api/misc/#FastDEQ.DeepEquilibriumSolution","page":"Miscellaneous","title":"FastDEQ.DeepEquilibriumSolution","text":"DeepEquilibriumSolution(z_star, u₀, residual, jacobian_loss, nfe)\n\nStores the solution of a DeepEquilibriumNetwork and its variants.\n\nFields\n\nz_star: Steady-State or the value reached due to maxiters\nu₀: Initial Condition\nresidual: Difference of the z^* and f(z^* x)\njacobian_loss: Jacobian Stabilization Loss (see individual networks to see how it can be computed)\nnfe: Number of Function Evaluations\n\n\n\n\n\n","category":"type"},{"location":"api/misc/#FastDEQ.get_and_clear_nfe!","page":"Miscellaneous","title":"FastDEQ.get_and_clear_nfe!","text":"get_and_clear_nfe!(model::AbstractDeepEquilibriumNetwork)\n\nReturn the number of function evaluations (NFE) and clear the counter.\n\n\n\n\n\n","category":"function"},{"location":"api/misc/#FastDEQ.compute_deq_jacobian_loss","page":"Miscellaneous","title":"FastDEQ.compute_deq_jacobian_loss","text":"compute_deq_jacobian_loss(re, p, z, x)\n\nComputes Jacobian Stabilization Loss (Shaojie Bai, Vladlen Koltun, J Zico Kolter (2021)).\n\nArguments\n\nre: Constructs the model given the parameters p.\np: Parameters of the model.\nz: Steady State.\nx: Input to the model.\n\nCurrent Known Failure Modes\n\nConv layers error out due to ForwardDiff on GPUs\nIf the model internally uses destructure/restructure eg. WeightNorm Layer, then this loss function will error out in the backward pass.\n\n\n\n\n\n","category":"function"},{"location":"api/misc/#FastDEQ.NormalInitializer","page":"Miscellaneous","title":"FastDEQ.NormalInitializer","text":"NormalInitializer(μ = 0.0f0, σ² = 0.01f0)\n\nInitializes the weights of the network with a normal distribution. For DEQs the training is stable if we use this as the Initialization\n\n\n\n\n\n","category":"function"},{"location":"api/misc/#FastDEQ.SupervisedLossContainer","page":"Miscellaneous","title":"FastDEQ.SupervisedLossContainer","text":"SupervisedLossContainer(loss_function)\nSupervisedLossContainer(loss_function, λ, λⱼ)\n\nA container class for supervised loss functions.\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#Dynamical-System-Variants","page":"Dynamical Systems","title":"Dynamical System Variants","text":"","category":"section"},{"location":"api/solvers/","page":"Dynamical Systems","title":"Dynamical Systems","text":"Shaojie Bai, J. Zico Kolter, Vladlen Koltun (2019) introduced Discrete Deep Equilibrium Models which drives a Discrete Dynamical System to its steady-state. Avik Pal, Alan Edelman, Christopher Rackauckas (2022) extends this framework to Continuous Dynamical Systems which converge to the steady-stable in a more stable fashion. For a detailed discussion refer to Avik Pal, Alan Edelman, Christopher Rackauckas (2022).","category":"page"},{"location":"api/solvers/#Continuous-DEQs-(Infinite-Time-Neural-ODEs)","page":"Dynamical Systems","title":"Continuous DEQs (Infinite Time Neural ODEs)","text":"","category":"section"},{"location":"api/solvers/","page":"Dynamical Systems","title":"Dynamical Systems","text":"ContinuousDEQSolver","category":"page"},{"location":"api/solvers/#FastDEQ.ContinuousDEQSolver","page":"Dynamical Systems","title":"FastDEQ.ContinuousDEQSolver","text":"ContinuousDEQSolver(alg=VCABM4(); mode::Symbol=:rel_deq_default, abstol=1e-8, reltol=1e-8, tspan=Inf)\n\nSolver for Continuous DEQ Problem (Avik Pal, Alan Edelman, Christopher Rackauckas (2022)). Similar to DynamicSS but provides more flexibility needed for solving DEQ problems.\n\nArguments\n\nalg: Algorithm to solve the ODEProblem. (Default: VCABM4())\nmode: Termination Mode of the solver. See below for a description of the various termination conditions (Default: :rel_deq_default)\nabstol: Absolute tolerance for termination. (Default: 1e-8)\nreltol: Relative tolerance for termination. (Default: 1e-8)\ntspan: Time span. Users should not change this value, instead control termination through maxiters in solve (Default: Inf)\n\nTermination Modes\n\nTermination on Absolute Tolerance\n\n:abs: Terminates if all left(  fracpartial upartial t  leq abstol right)\n:abs_norm: Terminates if  fracpartial upartial t  leq abstol\n:abs_deq_default: Essentially abs_norm + terminate if there has been no improvement for the last 30 steps + terminate if the solution blows up (diverges)\n:abs_deq_best: Same as :abs_deq_default but uses the best solution found so far, i.e. deviates only if the solution has not converged\n\nTermination on Relative Tolerance\n\n:rel: Terminates if all left( fracpartial upartial t  leq reltol times  u  right)\n:rel_norm: Terminates if  fracpartial upartial t  leq reltol times  fracpartial upartial t + u \n:rel_deq_default: Essentially rel_norm + terminate if there has been no improvement for the last 30 steps + terminate if the solution blows up (diverges)\n:rel_deq_best: Same as :rel_deq_default but uses the best solution found so far, i.e. deviates only if the solution has not converged\n\nTermination using both Absolute and Relative Tolerances\n\n:norm: Terminates if  fracpartial upartial t  leq reltol times  fracpartial upartial t + u  &           fracpartial upartial t  leq abstol\nfallback: Check if all values of the derivative is close to zero wrt both relative and absolute tolerance. This is usable for small problems             but doesn't scale well for neural networks, and should be avoided unless absolutely necessary\n\nSee also: DiscreteDEQSolver\n\nnote: Note\nThis  will be upstreamed to DiffEqSensitivity in the later releases of the package\n\n\n\n\n\n","category":"type"},{"location":"api/solvers/#Discrete-DEQs","page":"Dynamical Systems","title":"Discrete DEQs","text":"","category":"section"},{"location":"api/solvers/","page":"Dynamical Systems","title":"Dynamical Systems","text":"DiscreteDEQSolver","category":"page"},{"location":"api/solvers/#FastDEQ.DiscreteDEQSolver","page":"Dynamical Systems","title":"FastDEQ.DiscreteDEQSolver","text":"DiscreteDEQSolver(solver=LimitedMemoryBroydenSolver; abstol=1e-8, reltol=1e-8, kwargs...)\n\nSolver for Discrete DEQ Problem (Shaojie Bai, J. Zico Kolter, Vladlen Koltun (2019)). A wrapper around SSrootfind to mimic the ContinuousDEQSolver API. \n\nArguments\n\nsolver: NonLinear Solver for the DEQ problem. (Default: LimitedMemoryBroydenSolver)\nabstol: Absolute tolerance for termination. (Default: 1e-8)\nreltol: Relative tolerance for termination. (Default: 1e-8)\nkwargs: Additional keyword arguments passed to the solver.\n\nnote: Note\nThere is no mode kwarg for DiscreteDEQSolver. Instead solvers directly define their own termination condition. For BroydenSolver and LimitedMemoryBroydenSolver, the termination conditions are :abs_norm & :rel_deq_default respectively.\n\nSee also: ContinuousDEQSolver\n\n\n\n\n\n","category":"function"}]
}
